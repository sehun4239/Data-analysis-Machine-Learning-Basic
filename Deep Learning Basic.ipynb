{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "loss: 0.8493626117706299\n",
      "loss: 0.33402884006500244\n",
      "loss: 0.21700645983219147\n",
      "loss: 0.16227209568023682\n",
      "loss: 0.1295536756515503\n",
      "loss: 0.10763673484325409\n",
      "loss: 0.09191735088825226\n",
      "loss: 0.08010208606719971\n",
      "loss: 0.0709078311920166\n",
      "loss: 0.0635576918721199\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         3\n",
      "         1.0       1.00      1.00      1.00         1\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "\n",
    "# TF 1.15버전으로 GATE연산을 수행 (AND, OR)\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Training Data Set\n",
    "x_data = np.array([[0,0],\n",
    "                   [0,1],\n",
    "                   [1,0],\n",
    "                   [1,1]], dtype=np.float32)\n",
    "\n",
    "t_data = np.array([[0],[0],[0],[1]], dtype=np.float32)\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random.normal([2,1]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit,\n",
    "                                                              labels=T))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-2).minimize(loss)\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(30000):\n",
    "    _, loss_val = sess.run([train, loss], feed_dict={X:x_data, T:t_data})\n",
    "    \n",
    "    if step % 3000 == 0:\n",
    "        print('loss: {}'.format(loss_val))\n",
    "        \n",
    "# 성능평가(Accuracy)\n",
    "accuracy = tf.cast(H >= 0.5, dtype=tf.float32)\n",
    "result = sess.run(accuracy, feed_dict={X:x_data})\n",
    "print(classification_report(t_data.ravel(), result.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.4875164031982422\n",
      "loss: 0.18191032111644745\n",
      "loss: 0.12123686820268631\n",
      "loss: 0.08987502753734589\n",
      "loss: 0.07096492499113083\n",
      "loss: 0.05842010676860809\n",
      "loss: 0.04953435808420181\n",
      "loss: 0.0429324209690094\n",
      "loss: 0.03784545883536339\n",
      "loss: 0.033812109380960464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         1\n",
      "         1.0       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OR GATE\n",
    "\n",
    "# Training Data Set\n",
    "x_data = np.array([[0,0],\n",
    "                   [0,1],\n",
    "                   [1,0],\n",
    "                   [1,1]], dtype=np.float32)\n",
    "\n",
    "t_data = np.array([[0],[1],[1],[1]], dtype=np.float32)\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random.normal([2,1]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit,\n",
    "                                                              labels=T))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-2).minimize(loss)\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(30000):\n",
    "    _, loss_val = sess.run([train, loss], feed_dict={X:x_data, T:t_data})\n",
    "    \n",
    "    if step % 3000 == 0:\n",
    "        print('loss: {}'.format(loss_val))\n",
    "        \n",
    "# 성능평가(Accuracy)\n",
    "accuracy = tf.cast(H >= 0.5, dtype=tf.float32)\n",
    "result = sess.run(accuracy, feed_dict={X:x_data})\n",
    "print(classification_report(t_data.ravel(), result.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5767127871513367\n",
      "loss: 0.2770824432373047\n",
      "loss: 0.19237452745437622\n",
      "loss: 0.1481122076511383\n",
      "loss: 0.12028731405735016\n",
      "loss: 0.10109463334083557\n",
      "loss: 0.08705627918243408\n",
      "loss: 0.07635275274515152\n",
      "loss: 0.06793168187141418\n",
      "loss: 0.061140529811382294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         1\n",
      "         1.0       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# NAND gate\n",
    "\n",
    "# Training Data Set\n",
    "x_data = np.array([[0,0],\n",
    "                   [0,1],\n",
    "                   [1,0],\n",
    "                   [1,1]], dtype=np.float32)\n",
    "\n",
    "t_data = np.array([[1],[1],[1],[0]], dtype=np.float32)\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random.normal([2,1]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit,\n",
    "                                                              labels=T))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-2).minimize(loss)\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(30000):\n",
    "    _, loss_val = sess.run([train, loss], feed_dict={X:x_data, T:t_data})\n",
    "    \n",
    "    if step % 3000 == 0:\n",
    "        print('loss: {}'.format(loss_val))\n",
    "        \n",
    "# 성능평가(Accuracy)\n",
    "accuracy = tf.cast(H >= 0.5, dtype=tf.float32)\n",
    "result = sess.run(accuracy, feed_dict={X:x_data})\n",
    "print(classification_report(t_data.ravel(), result.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7929380536079407\n",
      "loss: 0.6960769295692444\n",
      "loss: 0.6932281255722046\n",
      "loss: 0.6931501626968384\n",
      "loss: 0.6931473612785339\n",
      "loss: 0.6931471824645996\n",
      "loss: 0.6931471824645996\n",
      "loss: 0.6931471824645996\n",
      "loss: 0.6931472420692444\n",
      "loss: 0.6931471228599548\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.50      0.67         2\n",
      "         1.0       0.67      1.00      0.80         2\n",
      "\n",
      "    accuracy                           0.75         4\n",
      "   macro avg       0.83      0.75      0.73         4\n",
      "weighted avg       0.83      0.75      0.73         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XOR (exclusive or 다르면 1 같으면 0)\n",
    "\n",
    "\n",
    "# Training Data Set\n",
    "x_data = np.array([[0,0],\n",
    "                   [0,1],\n",
    "                   [1,0],\n",
    "                   [1,1]], dtype=np.float32)\n",
    "\n",
    "t_data = np.array([[0],[1],[1],[0]], dtype=np.float32)\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W = tf.Variable(tf.random.normal([2,1]), name='weight')\n",
    "b = tf.Variable(tf.random.normal([1]), name='bias')\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(X,W) + b\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit,\n",
    "                                                              labels=T))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-2).minimize(loss)\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(30000):\n",
    "    _, loss_val = sess.run([train, loss], feed_dict={X:x_data, T:t_data})\n",
    "    \n",
    "    if step % 3000 == 0:\n",
    "        print('loss: {}'.format(loss_val))\n",
    "        \n",
    "# 성능평가(Accuracy)\n",
    "accuracy = tf.cast(H >= 0.5, dtype=tf.float32)\n",
    "result = sess.run(accuracy, feed_dict={X:x_data})\n",
    "print(classification_report(t_data.ravel(), result.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "loss: 1.1070748567581177\n",
      "loss: 0.3048502206802368\n",
      "loss: 0.11533050239086151\n",
      "loss: 0.06172015890479088\n",
      "loss: 0.040312476456165314\n",
      "loss: 0.02935217320919037\n",
      "loss: 0.022839466109871864\n",
      "loss: 0.01857670024037361\n",
      "loss: 0.015592454001307487\n",
      "loss: 0.013397473841905594\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00         2\n",
      "         1.0       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "\n",
    "# TF 1.15버전으로 GATE연산을 수행하는 Deep Learning으로 구현해보자\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Training Data Set\n",
    "x_data = np.array([[0,0],\n",
    "                   [0,1],\n",
    "                   [1,0],\n",
    "                   [1,1]], dtype=np.float32)\n",
    "\n",
    "t_data = np.array([[0],[1],[1],[0]], dtype=np.float32)\n",
    "\n",
    "# placeholder\n",
    "X = tf.placeholder(shape=[None,2], dtype=tf.float32)\n",
    "T = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "\n",
    "# Weight & bias\n",
    "W2 = tf.Variable(tf.random.normal([2,100]), name='weight2')\n",
    "b2 = tf.Variable(tf.random.normal([100]), name='bias2')\n",
    "layer2 = tf.sigmoid(tf.matmul(X,W2) + b2)\n",
    "\n",
    "W3 = tf.Variable(tf.random.normal([100,6]), name='weight3')\n",
    "b3 = tf.Variable(tf.random.normal([6]), name='bias3')\n",
    "layer3 = tf.sigmoid(tf.matmul(layer2,W3) + b3)\n",
    "\n",
    "W4 = tf.Variable(tf.random.normal([6,1]), name='weight4')\n",
    "b4 = tf.Variable(tf.random.normal([1]), name='bias4')\n",
    "\n",
    "# Hypothesis\n",
    "logit = tf.matmul(layer3,W4) + b4\n",
    "H = tf.sigmoid(logit)\n",
    "\n",
    "# loss function\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logit,\n",
    "                                                              labels=T))\n",
    "\n",
    "# train\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=1e-2).minimize(loss)\n",
    "\n",
    "# session, 초기화\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# 학습\n",
    "for step in range(30000):\n",
    "    _, loss_val = sess.run([train, loss], feed_dict={X:x_data, T:t_data})\n",
    "    \n",
    "    if step % 3000 == 0:\n",
    "        print('loss: {}'.format(loss_val))\n",
    "        \n",
    "# 성능평가(Accuracy)\n",
    "accuracy = tf.cast(H >= 0.5, dtype=tf.float32)\n",
    "result = sess.run(accuracy, feed_dict={X:x_data})\n",
    "print(classification_report(t_data.ravel(), result.ravel()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env] *",
   "language": "python",
   "name": "conda-env-data_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
